## ModÃ¨les linÃ©aires

On a deux types de modÃ¨les linÃ©aires.
### ModÃ¨le de logistic rÃ©gression binaire

UtilisÃ©s pour des problÃ¨mes de classification binaire. Par exemple,  si on veut classifier deux types de poisson Ã  partir d'un vecteur de features comme $mat("lumiÃ¨re"; "taille")$.

On applique la fonction sigmoÃ¯de :
$$ p(y = 1|x_1, x_2, ..., x_i) = 1/(1 + e^(-(a_0 + a_1 x_1 + ... + a_i x_i)) $$
Et on dÃ©termine $$ y_"pred" = cases(1 "si" p(y = 1|x) >= 0.5, 0 "sinon")$$
**Comment dÃ©terminer les paramÃ¨tres du modÃ¨le ?**

Ici on utilise la fonction de loss d'entropie croisÃ©e ! En fait, elle vient de ce qu'on a vu en probabilitÃ©s et statistiques avec la mÃ©thode du likelihood :

> [!question] d'oÃ¹ vient la cross entropy loss ?
> 
> On a donc deux coins, deux distributions :
> - le vrai coin **1**, avec comme distribution $1/2$, $1/2$
> - notre coin modÃ©lisÃ© **2**, qui cherche Ã  se rapprocher de la distribution du coin 1 (parce qu'on ne connaÃ®t pas la distribution du coin **1** bien sÃ»r, on cherche Ã  s'en rapprocher Ã  partir de ce qu'on observe). On dÃ©finit au dÃ©but nos poids Ã  $0.55$, $0.45$ par exemple.
>  
>  Avec des donnÃ©es d'entraÃ®nement, comme l'observation `H H T H T`, on peut calculer :
>  $$ t = P("observation" | "vrai coin")/P("observation" | "coin modÃ©lisÃ©") = P_"v"/P_"c" = (p_1^(N_H) dot p_2^(N_T))/(q_1^(N_H) dot q_2^(N_T)) $$
>  avec $p_1, q_1$ la probabilitÃ© d'avoir un head avec le coin 1 et le coin 2 respectivement et mÃªme chose pour $p_2, q_2$ pour tail, puis $N_H, N_T$ le nombre de head et tail observÃ©s respectivement.
>  
>  On normalise $T = (P_"v"/P_"c")^(1/n)$ puis on applique le log : $T_"log" = 1/n log(P_"v"/P_"c")$, puis les prop du log :
>  $$ T_"log" = N_H/N log(p_1) + N_T/N log(p_2) - N_H/N log(q_1) - N_T/N log(q_2) $$
>  
>  LÃ , on peut faire la simplification suivante : avec $N$ qui va Ã  l'infini $N_H/N$, va Ãªtre trÃ¨s prÃ¨s de la vraie probabilitÃ© d'avoir un head, et pareil pour $N_T/N$ donc :
>  $$ lim_((N, N_H, N_T) -> infinity) T_"log" = p_1 log(p_1) + p_2 log(p_2) - p_1 log(q_1) - p_2 log(q_2) $$
>  Et en rÃ©arrageant les termes :
>  $$ lim_((N, N_H, N_T) -> infinity) T_"log" = p_1 log(p_1/q_1) + p_2 log(p_2/q_2) = D_(K L) (P | | Q) = sum_i P(i) log(P(i)/Q(i)) $$
> 
> > [!question] Pourquoi $D_(K L )$ est une bonne mesure de la distance ?
> > C'est une bonne mesure de la distance entre les deux distributions $P$ et $Q$.
> > - Si les deux sont exactement Ã©gales, le ratio sera de **1** et le log sera Ã©gal Ã  zÃ©ro.
> > - Si $Q$ est trÃ¨s diffÃ©rent de $P$, alors forcÃ©ment, certains $q_i$ seront plus petits que
> >   certains $p_i$, ce qui fera augmenter trÃ¨s fortement la somme (en effet les termes de $q_i$ un peu plus grand que ceux de $p_i$, eux, diminuent moins la somme Ã  cause de la forme du $log$). c'est pour Ã§a d'ailleurs que $D_(K L) >= 0$ !
> >   
> >   $$ D_(K L) (P | | Q) = sum_i â€‹P(i)log(Q(i)/P(i)) â€‹>= log (sum_i â€‹P(i) dot Q(i)/P(i))â€‹ \ = log sum_i P(i)= log 1 = 0 $$
> >   
 > ![[assets/image-35.png|198x71]]
>  
>  > [!info] tout ce Ã  quoi on vient d'arriver tient aussi avec plus de deux classes !
> 
> Nous on veut donc minimiser cette distance $D_(K L)$.
> 
> $$ D_(K L) (P_"true" | P_"pred") = sum_y P_"true" (y | x_i) log((P_"true" (y | x_i))/(P_"pred"(y | x_i ; " " theta))) \ = sum_y P_"true" (y | x_i) log(P_"true" (y | x_i)) - P_"true" (y | x_i) log(P_"pred" (y | x_i ; " " theta)) $$
> 
> Or ici tout le premier terme est inutile, il ne dÃ©pend pas de $theta$ !
> 
> On retrouve donc $$ "argmin"_theta D_(K L) (P_"true" | | P_"pred") = "argmin"_theta - sum_y P_"true" (y | x_i) log(P_"pred" (y | x_i; " " theta)) $$
> 
> La formule de l'entropie croisÃ©e ! 

### Perceptron

Nous voulons minimiser : $$ E(\tilde{w}) = - \sum_{n = 1}^{N} sign(\tilde{w} \cdot \tilde{x_n}) t_n $$
oÃ¹ $t_n$ est la vraie valeur.

**Comment ?**
- commencer par dÃ©finir $\tilde{w}_1$ Ã  0.
- de faÃ§on itÃ©rative, choisir un indice $n$
	- si $x_n$ est correctement classifiÃ©, ne rien faire.
	- sinon, $\tilde{w}_{t + 1} = \tilde{w_t} + t_n \tilde{x_n}$

**Centered perceptron** : on shift tous nos points de telle sorte Ã  ce que notre dÃ©cision boundary passe par l'origine.

**Convergence Theorem** : dans un problÃ¨me de classification, s'il existe une marge $gamma$ telle qu'on ait une classification parfaite, le perceptron algorithm fait au plus $R^2/gamma^2$ erreurs (avec $R = max(|x_n|)$ ).

Parfois, pour un $gamma$ trÃ¨s petit ou quand la classification ne peut pas Ãªtre parfaite, on ne doit pas aller point par point dans l'ordre vÃ©rifier s'il est correctement classifiÃ©, mais les vÃ©rifier de faÃ§on **alÃ©atoire**.

Un problÃ¨me avec le perceptron, c'est qu'on dit que le rÃ©sultat est $-1$ ou $1$. Donc l'algorithme considÃ¨re que ces deux rÃ©sultats sont Ã©quivalents, de mÃªme que la ligne en diagonale qui serait bien meilleure :

![[assets/image-12.png|267x219]]

Ce qu'il faudrait, c'est avoir une fonction plus smooth :

![[assets/image-13.png|416x225]]


![[assets/image-14.png|385x294]]

![[assets/image-15.png|396x263]]

Sensitive to outliers. We have to accept that some points get missclassified.
On prÃ©fÃ¨re la sÃ©lection du bas !

![[assets/image-43.png|409x251]]

On dÃ©finit la marge comme ceci. On veut maximiser la marge, quitte Ã  ignorer quelques outliers. La regression logistique ne garantie pas du tout Ã§a.
### ModÃ¨le de logistic regression multiclass

On peut soit utiliser $D_(K L)$ soit softmax. 

## Que faire quand on a des donnÃ©es non sÃ©parables linÃ©airement ?

On peut combiner des classifiers linÃ©aires.

![[assets/image-47.png]]
![[assets/image-49.png]]
![[assets/image-52.png]]
![[assets/image-53.png]]


## Mesurer les performances d'un modÃ¨le

### Matrice de confusion

C'est un tableau qui compare les prÃ©dictions par rapport aux valeurs rÃ©elles.

|              | **PrÃ©dit : 0**          | **PrÃ©dit : 1**          |
| ------------ | ----------------------- | ----------------------- |
| **RÃ©el : 0** | **TN** (Vrais NÃ©gatifs) | **FP** (Faux Positifs)  |
| **RÃ©el : 1** | **FN** (Faux NÃ©gatifs)  | **TP** (Vrais Positifs) |
### PrÃ©cision

RÃ©pond Ã  la question : **"Parmi les prÃ©dictions positives du modÃ¨le, combien sont correctes ?"**

$$ "PrÃ©cision = " = "# vrais positifs"/("# vrais positifs" + "# faux nÃ©gatifs") $$
![[assets/image-164.png|254x447]]
### Accuracy

Le **recall** (ou **sensibilitÃ©**) est une mÃ©trique qui mesure la capacitÃ© dâ€™un modÃ¨le Ã  identifier correctement les **cas positifs**.

$$ "exactitude" = "# vraies prÃ©dictions"/"# total des prÃ©dictions"$$

|               |                                                            |                                                             |                                                                                             |
| ------------- | ---------------------------------------------------------- | ----------------------------------------------------------- | ------------------------------------------------------------------------------------------- |
| **PrÃ©cision** | $$(T P)/(T P + F P)$$â€‹                                     | "Parmi les prÃ©dictions positives, combien sont correctes ?" | Quand les **faux positifs** sont coÃ»teux (ex : filtrage de spam, faux diagnostics mÃ©dicaux) |
| **Accuracy**  | $$"# prÃ©dictions correctes"/("# total des prÃ©dictions")$$â€‹ | "Globalement, combien de prÃ©dictions sont correctes ?"      | Si les classes sont **Ã©quilibrÃ©es** (ex : reconnaissance faciale)                           |
| **Recall**    | $$(T P)/(T P + F N)$$â€‹                                     | "Parmi tous les vrais positifs, combien ont Ã©tÃ© dÃ©tectÃ©s ?" | Quand les **faux nÃ©gatifs** sont critiques (ex : dÃ©tection de maladies, sÃ©curitÃ©)           |
Le **F1 Score** est une moyenne harmonique entre la prÃ©cision et le recall, ce qui signifie quâ€™un modÃ¨le avec une prÃ©cision trÃ¨s Ã©levÃ©e mais un recall faible (ou inversement) aura un **F1-score faible**. 

$$ F_1 = 2 dot ("PrÃ©cision" dot "Recall")/("PrÃ©cision + Recall") $$

### MSE Loss function

$$ "MSE" = 1/N sum_(i = 1)^(N_t) (y_"pred-i" - y_i)^2 $$
Comment le dÃ©river ?
$$ L = 1/N sum_i (X W - Y)_i^2 \ = 1/N sum_i (X W - Y)_i^T (X W - Y)_i \ => nabla_W L = 1/N X^T (X W - Y) $$

## Arbres de dÃ©cisions

- **root node** : reprÃ©sente la population entiÃ¨re et se divise en sous-ensembles
- **splitting** : diviser un noeud en plusieurs autres noeuds en se basant sur un critÃ¨re
- **decision node** : quand un noeud a plusieurs enfants
- **leaf/terminal node** : quand il n'a pas d'enfants
- **pruning** : quand on enlÃ¨ve un decision node de l'arbre


La difficultÃ© est de choisir les dÃ©cisions rules. Pour Ã§a, on va itÃ©rer sur toutes les dÃ©cisions rules possibles, et voir l'information gagnÃ©e.

**Comment mesurer l'information gagnÃ©e ?** On peut utiliser une mesure comme Gini impurity qui va mesurer Ã  quel point notre groupe est composÃ©e d'une classe unique (est pur).
Information gagnÃ©e : impurity du parent - impurity des enfants (weighted)

On a souvent de l'over fitting : on dÃ©finit souvent un max depth.

## ğŸŒ² 2. **Random Forests**

### ğŸ§  IdÃ©e

Un **ensemble dâ€™arbres de dÃ©cision** construits sur des **sous-Ã©chantillons alÃ©atoires** des donnÃ©es (avec remplacement, câ€™est le **bagging**).

![[assets/image-33.png]]

Arrention Ã  bien sÃ©lectionner **avec replacement**, sinon tous les arbres se ressembleraient et on ne gagnerait pas beaucoup.

Chaque arbre est diffÃ©rent car :
- Il est entraÃ®nÃ© sur un jeu de donnÃ©es diffÃ©rent. (**bootstrapped dataset**)
- Ã€ chaque nÅ“ud, on ne considÃ¨re quâ€™un **sous-ensemble alÃ©atoire de features**.
### âœ… Avantages

- **Moins dâ€™overfitting** que les arbres seuls.
- **Robuste** aux bruits.
- Peut estimer la probabilitÃ© d'appartenance Ã  une classe.

Pour classifier, on demande Ã  chaque tree de classifier et on prend le plus de votes. On aggrege les donnÃ©es. **Bootstrapped dataset + aggregation = bagging**.

Les donnÃ©es qui ne finissent dans aucun arbre s'appellent des **Out-of-Bag Datasets**. On peut mesurer l'accuracy de notre modÃ¨le en utilisant les out-of-bags dataset (on fait prÃ©dire Ã  notre arbre les valeurs de out of bags).

---

## ğŸš€ 3. **Gradient Boosted Trees (GBT, ou XGBoost, LightGBM)**

### ğŸ§  IdÃ©e

On ajoute **des arbres faibles un par un** pour corriger les erreurs du modÃ¨le prÃ©cÃ©dent. Câ€™est une approche **sÃ©quentielle**.

- Ã€ chaque Ã©tape, on construit un nouvel arbre pour prÃ©dire **les rÃ©sidus (erreurs)** du modÃ¨le courant.
    
- On **ajuste progressivement**, un peu comme un apprentissage par descente de gradient.
    

### ğŸ”§ DÃ©tails :

- On utilise un **taux dâ€™apprentissage (shrinkage)** pour Ã©viter lâ€™overfitting.
    
- TrÃ¨s puissant, souvent **top 1 sur Kaggle**, mais plus sensible aux rÃ©glages.


