## Mod√®les lin√©aires

On a deux types de mod√®les lin√©aires.
### Mod√®le de logistic r√©gression binaire

Utilis√©s pour des probl√®mes de classification binaire. Par exemple,  si on veut classifier deux types de poisson √† partir d'un vecteur de features comme $mat("lumi√®re"; "taille")$.

On applique la fonction sigmo√Øde :
$$ p(y = 1|x_1, x_2, ..., x_i) = 1/(1 + e^(-(a_0 + a_1 x_1 + ... + a_i x_i)) $$
Et on d√©termine $$ y_"pred" = cases(1 "si" p(y = 1|x) >= 0.5, 0 "sinon")$$
**Comment d√©terminer les param√®tres du mod√®le ?**

Ici on utilise la fonction de loss d'entropie crois√©e ! En fait, elle vient de ce qu'on a vu en probabilit√©s et statistiques avec la m√©thode du likelihood :

> [!question] d'o√π vient la cross entropy loss ?
> 
> On a donc deux coins, deux distributions :
> - le vrai coin **1**, avec comme distribution $1/2$, $1/2$
> - notre coin mod√©lis√© **2**, qui cherche √† se rapprocher de la distribution du coin 1 (parce qu'on ne conna√Æt pas la distribution du coin **1** bien s√ªr, on cherche √† s'en rapprocher √† partir de ce qu'on observe). On d√©finit au d√©but nos poids √† $0.55$, $0.45$ par exemple.
>  
>  Avec des donn√©es d'entra√Ænement, comme l'observation `H H T H T`, on peut calculer :
>  $$ t = P("observation" | "vrai coin")/P("observation" | "coin mod√©lis√©") = P_"v"/P_"c" = (p_1^(N_H) dot p_2^(N_T))/(q_1^(N_H) dot q_2^(N_T)) $$
>  avec $p_1, q_1$ la probabilit√© d'avoir un head avec le coin 1 et le coin 2 respectivement et m√™me chose pour $p_2, q_2$ pour tail, puis $N_H, N_T$ le nombre de head et tail observ√©s respectivement.
>  
>  On normalise $T = (P_"v"/P_"c")^(1/n)$ puis on applique le log : $T_"log" = 1/n log(P_"v"/P_"c")$, puis les prop du log :
>  $$ T_"log" = N_H/N log(p_1) + N_T/N log(p_2) - N_H/N log(q_1) - N_T/N log(q_2) $$
>  
>  L√†, on peut faire la simplification suivante : avec $N$ qui va √† l'infini $N_H/N$, va √™tre tr√®s pr√®s de la vraie probabilit√© d'avoir un head, et pareil pour $N_T/N$ donc :
>  $$ lim_((N, N_H, N_T) -> infinity) T_"log" = p_1 log(p_1) + p_2 log(p_2) - p_1 log(q_1) - p_2 log(q_2) $$
>  Et en r√©arrageant les termes :
>  $$ lim_((N, N_H, N_T) -> infinity) T_"log" = p_1 log(p_1/q_1) + p_2 log(p_2/q_2) = D_(K L) (P | | Q) = sum_i P(i) log(P(i)/Q(i)) $$
> 
> > [!question] Pourquoi $D_(K L )$ est une bonne mesure de la distance ?
> > C'est une bonne mesure de la distance entre les deux distributions $P$ et $Q$.
> > - Si les deux sont exactement √©gales, le ratio sera de **1** et le log sera √©gal √† z√©ro.
> > - Si $Q$ est tr√®s diff√©rent de $P$, alors forc√©ment, certains $q_i$ seront plus petits que
> >   certains $p_i$, ce qui fera augmenter tr√®s fortement la somme (en effet les termes de $q_i$ un peu plus grand que ceux de $p_i$, eux, diminuent moins la somme √† cause de la forme du $log$). c'est pour √ßa d'ailleurs que $D_(K L) >= 0$ !
> >   
> >   $$ D_(K L) (P | | Q) = sum_i ‚ÄãP(i)log(Q(i)/P(i)) ‚Äã>= log (sum_i ‚ÄãP(i) dot Q(i)/P(i))‚Äã \ = log sum_i P(i)= log 1 = 0 $$
> >   
 > ![[assets/image-35.png|198x71]]
>  
>  > [!info] tout ce √† quoi on vient d'arriver tient aussi avec plus de deux classes !
> 
> Nous on veut donc minimiser cette distance $D_(K L)$.
> 
> $$ D_(K L) (P_"true" | P_"pred") = sum_y P_"true" (y | x_i) log((P_"true" (y | x_i))/(P_"pred"(y | x_i ; " " theta))) \ = sum_y P_"true" (y | x_i) log(P_"true" (y | x_i)) - P_"true" (y | x_i) log(P_"pred" (y | x_i ; " " theta)) $$
> 
> Or ici tout le premier terme est inutile, il ne d√©pend pas de $theta$ !
> 
> On retrouve donc $$ "argmin"_theta D_(K L) (P_"true" | | P_"pred") = "argmin"_theta - sum_y P_"true" (y | x_i) log(P_"pred" (y | x_i; " " theta)) $$
> 
> La formule de l'entropie crois√©e ! 

### Perceptron

Nous voulons minimiser : $$ E(\tilde{w}) = - \sum_{n = 1}^{N} sign(\tilde{w} \cdot \tilde{x_n}) t_n $$
o√π $t_n$ est la vraie valeur.

**Comment ?**
- commencer par d√©finir $\tilde{w}_1$ √† 0.
- de fa√ßon it√©rative, choisir un indice $n$
	- si $x_n$ est correctement classifi√©, ne rien faire.
	- sinon, $\tilde{w}_{t + 1} = \tilde{w_t} + t_n \tilde{x_n}$

**Centered perceptron** : on shift tous nos points de telle sorte √† ce que notre d√©cision boundary passe par l'origine.

**Convergence Theorem** : dans un probl√®me de classification, s'il existe une marge $gamma$ telle qu'on ait une classification parfaite, le perceptron algorithm fait au plus $R^2/gamma^2$ erreurs (avec $R = max(|x_n|)$ ).

Parfois, pour un $gamma$ tr√®s petit ou quand la classification ne peut pas √™tre parfaite, on ne doit pas aller point par point dans l'ordre v√©rifier s'il est correctement classifi√©, mais les v√©rifier de fa√ßon **al√©atoire**.

Un probl√®me avec le perceptron, c'est qu'on dit que le r√©sultat est $-1$ ou $1$. Donc l'algorithme consid√®re que ces deux r√©sultats sont √©quivalents, de m√™me que la ligne en diagonale qui serait bien meilleure :

![[assets/image-12.png|267x219]]

Ce qu'il faudrait, c'est avoir une fonction plus smooth :

![[assets/image-13.png|416x225]]


![[assets/image-14.png|385x294]]

![[assets/image-15.png|396x263]]

Sensitive to outliers. We have to accept that some points get missclassified.
On pr√©f√®re la s√©lection du bas !

![[assets/image-43.png|409x251]]

On d√©finit la marge comme ceci. On veut maximiser la marge, quitte √† ignorer quelques outliers. La regression logistique ne garantie pas du tout √ßa.
### Mod√®le de logistic regression multiclass

On peut soit utiliser $D_(K L)$ soit softmax. 

## Que faire quand on a des donn√©es non s√©parables lin√©airement ?

On peut combiner des classifiers lin√©aires.

![[assets/image-47.png]]
![[assets/image-49.png]]
![[assets/image-52.png]]
![[assets/image-53.png]]


## Mesurer les performances d'un mod√®le

### Matrice de confusion

C'est un tableau qui compare les pr√©dictions par rapport aux valeurs r√©elles.

|              | **Pr√©dit : 0**          | **Pr√©dit : 1**          |
| ------------ | ----------------------- | ----------------------- |
| **R√©el : 0** | **TN** (Vrais N√©gatifs) | **FP** (Faux Positifs)  |
| **R√©el : 1** | **FN** (Faux N√©gatifs)  | **TP** (Vrais Positifs) |
### Pr√©cision

R√©pond √† la question : **"Parmi les pr√©dictions positives du mod√®le, combien sont correctes ?"**

$$ "Pr√©cision = " = "# vrais positifs"/("# vrais positifs" + "# faux n√©gatifs") $$
![[assets/image-164.png|254x447]]
### Accuracy

Le **recall** (ou **sensibilit√©**) est une m√©trique qui mesure la capacit√© d‚Äôun mod√®le √† identifier correctement les **cas positifs**.

$$ "exactitude" = "# vraies pr√©dictions"/"# total des pr√©dictions"$$

|               |                                                            |                                                             |                                                                                             |
| ------------- | ---------------------------------------------------------- | ----------------------------------------------------------- | ------------------------------------------------------------------------------------------- |
| **Pr√©cision** | $$(T P)/(T P + F P)$$‚Äã                                     | "Parmi les pr√©dictions positives, combien sont correctes ?" | Quand les **faux positifs** sont co√ªteux (ex : filtrage de spam, faux diagnostics m√©dicaux) |
| **Accuracy**  | $$"# pr√©dictions correctes"/("# total des pr√©dictions")$$‚Äã | "Globalement, combien de pr√©dictions sont correctes ?"      | Si les classes sont **√©quilibr√©es** (ex : reconnaissance faciale)                           |
| **Recall**    | $$(T P)/(T P + F N)$$‚Äã                                     | "Parmi tous les vrais positifs, combien ont √©t√© d√©tect√©s ?" | Quand les **faux n√©gatifs** sont critiques (ex : d√©tection de maladies, s√©curit√©)           |
Le **F1 Score** est une moyenne harmonique entre la pr√©cision et le recall, ce qui signifie qu‚Äôun mod√®le avec une pr√©cision tr√®s √©lev√©e mais un recall faible (ou inversement) aura un **F1-score faible**. 

$$ F_1 = 2 dot ("Pr√©cision" dot "Recall")/("Pr√©cision + Recall") $$

### MSE Loss function

$$ "MSE" = 1/N sum_(i = 1)^(N_t) (y_"pred-i" - y_i)^2 $$
Comment le d√©river ?
$$ L = 1/N sum_i (X W - Y)_i^2 \ = 1/N sum_i (X W - Y)_i^T (X W - Y)_i \ => nabla_W L = 1/N X^T (X W - Y) $$

## Arbres de d√©cisions

- **root node** : repr√©sente la population enti√®re et se divise en sous-ensembles
- **splitting** : diviser un noeud en plusieurs autres noeuds en se basant sur un crit√®re
- **decision node** : quand un noeud a plusieurs enfants
- **leaf/terminal node** : quand il n'a pas d'enfants
- **pruning** : quand on enl√®ve un decision node de l'arbre


La difficult√© est de choisir les d√©cisions rules. Pour √ßa, on va it√©rer sur toutes les d√©cisions rules possibles, et voir l'information gagn√©e.

**Comment mesurer l'information gagn√©e ?** On peut utiliser une mesure comme Gini impurity qui va mesurer √† quel point notre groupe est compos√©e d'une classe unique (est pur).
Information gagn√©e : impurity du parent - impurity des enfants (weighted)

On a souvent de l'over fitting : on d√©finit souvent un max depth.

## üå≤ 2. **Random Forests**

### üß† Id√©e

Un **ensemble d‚Äôarbres de d√©cision** construits sur des **sous-√©chantillons al√©atoires** des donn√©es (avec remplacement, c‚Äôest le **bagging**).

![[assets/image-33.png]]

Arrention √† bien s√©lectionner **avec replacement**, sinon tous les arbres se ressembleraient et on ne gagnerait pas beaucoup.

Chaque arbre est diff√©rent car :
- Il est entra√Æn√© sur un jeu de donn√©es diff√©rent. (**bootstrapped dataset**)
- √Ä chaque n≈ìud, on ne consid√®re qu‚Äôun **sous-ensemble al√©atoire de features**.
### ‚úÖ Avantages

- **Moins d‚Äôoverfitting** que les arbres seuls.
- **Robuste** aux bruits.
- Peut estimer la probabilit√© d'appartenance √† une classe.

Pour classifier, on demande √† chaque tree de classifier et on prend le plus de votes. On aggrege les donn√©es. **Bootstrapped dataset + aggregation = bagging**.

Les donn√©es qui ne finissent dans aucun arbre s'appellent des **Out-of-Bag Datasets**. On peut mesurer l'accuracy de notre mod√®le en utilisant les out-of-bags dataset (on fait pr√©dire √† notre arbre les valeurs de out of bags).

---

## üöÄ 3. **Gradient Boosted Trees (GBT, ou XGBoost, LightGBM)**

### üß† Id√©e

On ajoute **des arbres faibles un par un** pour corriger les erreurs du mod√®le pr√©c√©dent. C‚Äôest une approche **s√©quentielle**.

- √Ä chaque √©tape, on construit un nouvel arbre pour pr√©dire **les r√©sidus (erreurs)** du mod√®le courant.
    
- On **ajuste progressivement**, un peu comme un apprentissage par descente de gradient.
    

### üîß D√©tails :

- On utilise un **taux d‚Äôapprentissage (shrinkage)** pour √©viter l‚Äôoverfitting.
    
- Tr√®s puissant, souvent **top 1 sur Kaggle**, mais plus sensible aux r√©glages.


